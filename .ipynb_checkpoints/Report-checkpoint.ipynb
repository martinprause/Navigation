{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will see the Banan Navigation Project for the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "## 1. Start the Environment\n",
    "\n",
    "Please install all dependencies as explained in the Getting Started section in the [README.MD](https://github.com/trobar/navigation/blob/master/README.md) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "env = UnityEnvironment(file_name=\"Banana_Windows_x86_64/Banana.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The Algorithm\n",
    "\n",
    "The algorithm is based on a Deep-Q-Learning Algorithms with experience replay and fixed-Q-targets. The algorithm conists\n",
    "of three main parts:\n",
    "    \n",
    "* A deep neural network, to map environment states to action values\n",
    "* An agent class to select an action using the neural network and update the neural network based on reward received from that action.\n",
    "* The training class which brings together the neural network and the agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Neural Network\n",
    "A simple deep neural network (2 hidden layers) is used to map states to action values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=64, fc2_units=64):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agent and ReplayBuffer\n",
    "The Agent class contains the following function\n",
    "\n",
    "* init: Initialize the two networks (local and target) and the Replay Buffer\n",
    "* step: The agent stores the results of the action, such as reward, new_state etc in the ReplayBuffer. If enough examples are stored in the ReplayBuffer it uses them to conduct a batch learning process.\n",
    "* act: Using an epsilon greedy policy the agent select the Q-action values from the local network \n",
    "* learn: Optimizes the local network using backpropagation (AdamOptimizer), but takes the Q-targets from the target network.\n",
    "* soft_update: Copies parameters from the local to the target network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            action_size (int): dimension of each action\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 128 #64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate \n",
    "UPDATE_EVERY = 10 #4        # how often to update the network\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "\n",
    "        # Q-Network\n",
    "        self.qnetwork_local = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.qnetwork_target = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
    "        self.t_step = 0\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        # Save experience in replay memory\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        # Learn every UPDATE_EVERY time steps.\n",
    "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
    "        if self.t_step == 0:\n",
    "            # If enough samples are available in memory, get random subset and learn\n",
    "            if len(self.memory) > BATCH_SIZE:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, GAMMA)\n",
    "\n",
    "    def act(self, state, eps=0.):\n",
    "        \"\"\"Returns actions for given state as per current policy.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state (array_like): current state\n",
    "            eps (float): epsilon, for epsilon-greedy action selection\n",
    "        \"\"\"\n",
    "        \n",
    "        #Get the state\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        \n",
    "        #Just a forward push to calculate the outputs\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state)\n",
    "        \n",
    "        #Activate training mode    \n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy()).astype(np.int32)\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update value parameters using given batch of experience tuples.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # Get max predicted Q values (for next states) from target model\n",
    "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        # Compute Q targets for current states \n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # ------------------- update target network ------------------- #\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            local_model (PyTorch model): weights will be copied from\n",
    "            target_model (PyTorch model): weights will be copied to\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Training Class\n",
    "The training class iterates over 1000 episodes. For each episode the environment is reset and every 100 episode the average score is displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dqn(n_episodes=1000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        state = env_info.vector_observations[0]\n",
    "        score = 0\n",
    "        \n",
    "        for t in range(max_t):\n",
    "            \n",
    "            action = agent.act(state, eps)\n",
    "            env_info = env.step(action)[brain_name]     \n",
    "            next_state = env_info.vector_observations[0] \n",
    "            reward = env_info.rewards[0]                   \n",
    "            done = env_info.local_done[0]\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            score += reward                              \n",
    "            state = next_state   \n",
    "            \n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. See a trained agent in action\n",
    "\n",
    "In the next code cell, you'll see a trained agent in action. \n",
    "\n",
    "Watch a video here: https://youtu.be/Uq9-nHRxtSU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "agent = Agent(state_size=s, action_size=a, seed=0)\n",
    "\n",
    "# load the neural networks\n",
    "agent.qnetwork_local.load_state_dict(torch.load('checkpoint_local.pth'))\n",
    "agent.qnetwork_target.load_state_dict(torch.load('checkpoint_target.pth'))\n",
    "\n",
    "# Load the ReplayBuffer\n",
    "with open('agent_memory.pkl', 'rb') as file:\n",
    "    agent.memory = pickle.load(file)\n",
    "\n",
    "# Disable training mode to view how the agent moves\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "state = env_info.vector_observations[0]\n",
    "score = 0\n",
    "\n",
    "scores = []                        \n",
    "scores_window = deque(maxlen=100)  \n",
    "    \n",
    "for i_episode in range(1, 1):\n",
    "    env_info = env.reset(train_mode=False)[brain_name]\n",
    "    state = env_info.vector_observations[0]\n",
    "    score = 0\n",
    "    for t in range(1000):\n",
    "        action = agent.act(state, 0)\n",
    "        env_info = env.step(action)[brain_name]     \n",
    "        next_state = env_info.vector_observations[0] \n",
    "        reward = env_info.rewards[0]                   \n",
    "        done = env_info.local_done[0]\n",
    "           \n",
    "        agent.step(state, action, reward, next_state, done)\n",
    "        score += reward                               \n",
    "        state = next_state   \n",
    "            \n",
    "        if done:\n",
    "            break \n",
    "    scores_window.append(score)       # save most recent score\n",
    "    scores.append(score)              # save most recent score\n",
    "    print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your own agent\n",
    "\n",
    "Watch a training video here: https://youtu.be/mRtfJDLXPhA\n",
    "\n",
    "The plot of the agent's performance shows that the benachmark of an average score of 13 has been reached after 600 episodes and converges to a score of 16 after 1000 episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.34\n",
      "Episode 200\tAverage Score: 3.13\n",
      "Episode 300\tAverage Score: 4.88\n",
      "Episode 400\tAverage Score: 8.67\n",
      "Episode 500\tAverage Score: 11.32\n",
      "Episode 600\tAverage Score: 14.48\n",
      "Episode 700\tAverage Score: 15.39\n",
      "Episode 800\tAverage Score: 15.54\n",
      "Episode 900\tAverage Score: 16.06\n",
      "Episode 1000\tAverage Score: 15.60\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import dill as pickle\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of actions\n",
    "a = brain.vector_action_space_size\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "s = len(state)\n",
    "\n",
    "\n",
    "agent = Agent(state_size=s , action_size= a, seed=0)\n",
    "\n",
    "scores = dqn()\n",
    "\n",
    "torch.save(agent.qnetwork_local.state_dict(), 'your_checkpoint_local.pth')\n",
    "torch.save(agent.qnetwork_target.state_dict(), 'your_checkpoint_target.pth')\n",
    "with open('your_agent_memory.pkl', 'wb') as file:\n",
    "    pickle.dump(agent.memory, file)\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Ideas\n",
    "\n",
    "Implement a double DQN, a dueling DQN, and/or prioritized experience replay."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
